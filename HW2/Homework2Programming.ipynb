{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">EE 381V: Statistical Machine Learning</p>\n",
    "# <p style=\"text-align: center;\">Homework 2: Programming Assignments</p>\n",
    "## <p style=\"text-align: center;\">Total points: 65  </p>\n",
    "## <p style=\"text-align: center;\">Due: March 8 by 11:59 pm (submission via Gradescope)</p>\n",
    "\n",
    "Ideally, your solution to the assignments should be written in and submitted as a **Jupyter notebook**. Please make sure your code runs and the graphics (along with anything else that you want to be considered) are displayed in your notebook before submitting.\n",
    "\n",
    "For the theoretical parts of the questions below (e.g., computation of gradients), the most convenient approach is to type the solution in the provided spaces (\"Markdown\" cells) using LaTeX (if not familiar with LaTeX, please check the markdown cells below stating questions for examples of writing equations in LaTeX). Alternatively, you could write down the solution on paper and submit a pdf file of the scan/photo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> Question 1: Stochastic Gradient Descent (20 pts) </font>\n",
    "    \n",
    "In class, we introduced gradient descent and its stochastic variant. In this problem, we will explore the latter. Assume that we want to predict values of two-dimensional feature vectors, i.e., we are given a dataset $\\{({\\bf x}_1,y_1),\\dots,({\\bf x}_N,y_N)\\}$ of features ${\\bf x}_i = [x_{i1} \\;\\; x_{i2}]^T$ and their corresponding values $y_i$, and would like to predict value $y$ of a never before seen ${\\bf x} = [x_{1} \\;\\; x_{2}]^T$.\n",
    "\n",
    " 1. (5 pts) Assuming that we want to learn the coefficients via stochastic gradient descent, derive the update rules for all 4 coefficients (i.e., $w_0$, $w_1$, $w_2$ and $w_3$) of the model \n",
    "$$y = w_0 + w_1x_1 + w_2x_1x_2 + w_3e^{-x_1}.$$ \n",
    "\n",
    "\n",
    " 2. (15 pts) Write a Python code that implements the SGD rules found in part (a) to train the non-linear model $$ y = w_0 + w_1x_1 + w_2x_1x_2 + w_3e^{-x_1}.$$ Attempt to format similarly to scikit-learn's models. The template of the class is given. The init function of the class takes as input the learning rate, regularization constant and number of epochs. The fit method must take as inputs X and y. The _predict_ method takes an X value (optionally, an array of values). Use your new gradient descent regression to train on data given in \"SGD_samples.csv\" for 15 epochs, using learning rates [0, .0001, .001, .01, 0.1, 1, 10, 100] and regularization (ridge regression) constants [0,10,100]. Plot the mean-square error (MSE) and $w$ parameters as functions of epoch (for 15 epochs) for the best 2 combinations of the learning_rate and regularization for SGD. Report the MSE at the end of 15 epochs for the two best combinations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "class Regression:\n",
    "    \n",
    "    def __init__(self, learning_rate, regularization, n_epoch):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epoch = n_epoch\n",
    "        self.regularization = regularization\n",
    "        \n",
    "    def sgd(self, gradient):\n",
    "        self.coef # = please fill this to update self.coef using SGD\n",
    "    \n",
    "        \n",
    "    def fit(self, X, y, update_rule='sgd', plot=False):\n",
    "        mse = []\n",
    "        coefs = []\n",
    "        X = self.get_features(X)\n",
    "        for epoch in range(self.n_epoch):\n",
    "            for i in range(X.shape[0]):\n",
    "                # Compute error\n",
    "                   #please fill this\n",
    "                # Compute gradients\n",
    "                    #please fill this\n",
    "               \n",
    "                # Update weights\n",
    "                self.sgd(gradient)\n",
    "\n",
    "            coefs.append(self.coef)\n",
    "            residuals = y - self.linearPredict(X)         \n",
    "            mse.append(np.mean(residuals**2))\n",
    "        self.lowest_mse = mse[-1]\n",
    "        if plot == True:\n",
    "            plt.figure()\n",
    "            plt.plot(range(self.n_epoch),mse)\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.figure()\n",
    "            coefs = np.array(coefs)\n",
    "            plt.plot(range(self.n_epoch),coefs[:,0],label='w0')\n",
    "            plt.plot(range(self.n_epoch),coefs[:,1],label='w1')\n",
    "            plt.plot(range(self.n_epoch),coefs[:,2],label='w2')\n",
    "            plt.plot(range(self.n_epoch),coefs[:,3],label='w3')\n",
    "            plt.legend()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('parameter value')\n",
    "\n",
    "    def get_features(self, X):\n",
    "        '''\n",
    "        this output of this function can be used to compute the gradient in `fit`\n",
    "        '''\n",
    "        x = np.zeros((X.shape[0], 4))\n",
    "        x[:,0] = 1\n",
    "        x[:,1] = X[:,0]\n",
    "        x[:,2] = X[:,0]*X[:,1]\n",
    "        x[:,3] = np.exp(-X[:,0])\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    #def linearPredict(self, X):  \n",
    "        #compute dot product of self.coef and X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SGD_samples.csv')\n",
    "X = np.array([data['x1'].values, data['x2'].values]).T\n",
    "y = data['y'].values\n",
    "n_epochs = 15\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "regularization = [0, 10, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Derive the coefficent updates for all 4 coefficients of the model (use Markdown to type) (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use tex to write your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write the code here (10pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore running the regression with different learning rates and regularization (use the class 'Regression' you completed in the previous section). Plot the required results. (5 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> Question 2: Regularized regression (25 pts)</font>\n",
    "In this question, we will explore the applications of ridge (i.e., $l_2$-norm) and lasso ($l_1$-norm) regularized regression using sklearn package in Python. To this end, we will use the dataset Fish.csv (posted to Canvas). The dataset is taken from https://www.kaggle.com/aungpyaeap/fish-market and includes 7 columns with 6 features (variables) of the fish and 1 target (label):\n",
    "\n",
    "x1: Species: Species name of fish (nonnumeric)\\\n",
    "x2: Length1: Vertical length in cm\\\n",
    "x3: Length2: Diagonal length in cm\\\n",
    "x4: Length3: Cross length in cm\\\n",
    "x5: Height: Height in cm\\\n",
    "x6: Width: Diagonal width in cm\n",
    "\n",
    "y: Weight of the fish in grams\n",
    "\n",
    "We want to learn the function $y = w_1x_1+w_2x_2+w_3x_3+w_4x_4+w_5x_5+w_6x_6$ to predict the weight of a fish from the features.\n",
    "\n",
    "* Use the below code to load the dataset. Create a train_test split of 75:25 with random state = 50\n",
    "\n",
    "* Scale the data so that each of the independent variables has zero mean and unit variance. You can use  [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-649ddea407b2>:9: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  df = df[~df.isin([0, np.nan, np.inf, -np.inf]).any(1)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Fish.csv\", index_col=0)\n",
    "df = df[~df.isin([0, np.nan, np.inf, -np.inf]).any(1)]\n",
    "\n",
    "X = df.drop(['Weight'], axis=1)\n",
    "y = df['Weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to run [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can create this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. The cross validation should happen on your training data using average MSE as the scoring metric. (5pts)\n",
    "\n",
    "b) Run ridge and lasso regression for all alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one figure each for lasso and ridge, so a total of two figures; the results for different features should be plotted in the same figure. What do you qualitatively observe as the value of the regularization parameter is changed? (5pts)\n",
    "\n",
    "c) Run the (unconstrained) linear regression and its regularized variants (both ridge and lasso) on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MAE) and the mean-squared error (MSE) on the test data for each method. (3pts)\n",
    "\n",
    "d) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross-validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross-validation. Run lasso on the training data using the best $\\lambda$ and report the coefficients for all variables. (3pts)\n",
    "\n",
    "e) Why did we have to scale the data before regularization? (3pts)\n",
    "\n",
    "f) Lasso and ridge regularization techniques are often used to combat overfitting during linear regression. Which of the two yields sparser models (i.e., fewer parameters) when the tuning parameter $\\lambda$ is large (but not infinite)? (3pts)\n",
    "\n",
    "g) [ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) is a type of a regression model that uses combined $l_1$ and $l_2$ priors as regularizers. Run ElasticNet with the same values of alphas on the training data, and find the best value for alpha based on the MSE. Report the MSE on test data and plot a graph showing the predicted and actual values/labels. Comment/compare the results of the three regression models. (3pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'> Question 3: Feature Selection (20 pts)</font>\n",
    "\n",
    "In this question, we will explore the importance of feature selection. You may use the code below to load the dataset \"zoo.csv\" which contains a set of features for different animals and the output variable (\"class_type\"). \n",
    "\n",
    "1. Show the correlation matrix for this dataset; its dimension should be n_features x n_features. List the top 5 most positively correlated features with class_type. (**3pts**)\n",
    "\n",
    "2. List top-5 most negatively correlated features with class_type. (**3pts**)\n",
    "\n",
    "3. Use https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE to perform feature selection with estimator = LogisticRegression(max_iter=1000). List the top 5 features selected by RFE. (**2pts**)\n",
    "\n",
    "To proceed, create a train_test split of 80:20 (training:test) with random state = 50. As part of the preprocessing, we should use [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html): Instead of fitting a model to the original data, we use StandardScaler to first center each feature ([Example](http://scikit-learn.org/stable/auto_examples/applications/plot_prediction_latency.html#sphx-glr-auto-examples-applications-plot-prediction-latency-py)). Remember that when dealing with training and testing data, we fit preprocessing parameters using training data and apply them to testing data. You should scale only the features (independent variables), not the target variable y.\n",
    "\n",
    "4. Train a [Linear Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) using training data and report the ${R^2}$ score on the test set for each of the following:\n",
    "\n",
    "   a) Model trained with top-5 most positvely correlated features from part 1. (**2pts**)\n",
    "   \n",
    "   b) Model trained with top-5 most negatively correlated features from part 2. (**2pts**)\n",
    "   \n",
    "   c) Model trained with five features selected by RFE in part 3. (**2pts**)\n",
    "   \n",
    "   d) Finally, train a linear regressor on the entire training data using all the original features. (**2pts**)\n",
    "\n",
    "\n",
    "5. Comment on your results.  (**4pts**) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import (train_test_split,KFold)\n",
    "\n",
    "df = pd.read_csv(\"zoo.csv\")\n",
    "df = df.drop(['animal_name'], axis = 1)\n",
    "meta_val = (df['class_type'] <= 4) + 0\n",
    "df['class_type']=meta_val\n",
    "\n",
    "y = df['class_type'].values\n",
    "X = df.drop(['class_type'], axis = 1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.20, random_state=50)\n",
    "\n",
    "\n",
    "df_corr = pd.DataFrame(X_train)\n",
    "df_corr['class_type'] = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airborne</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hair  feathers  eggs  milk  airborne  aquatic  predator  toothed  backbone  \\\n",
       "0     1         0     0     1         0        0         1        1         1   \n",
       "1     1         0     0     1         0        0         0        1         1   \n",
       "2     0         0     1     0         0        1         1        1         1   \n",
       "3     1         0     0     1         0        0         1        1         1   \n",
       "4     1         0     0     1         0        0         1        1         1   \n",
       "\n",
       "   breathes  venomous  fins  legs  tail  domestic  catsize  class_type  \n",
       "0         1         0     0     4     0         0        1           1  \n",
       "1         1         0     0     4     1         0        1           1  \n",
       "2         0         0     1     0     1         0        0           1  \n",
       "3         1         0     0     4     0         0        1           1  \n",
       "4         1         0     0     4     1         0        1           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANSWER "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
